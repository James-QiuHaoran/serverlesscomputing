<!doctype html>

<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Sixth International Workshop on Serverless Computing (WoSC) 2020</title>
  <meta name="description" content="Serverless Computing">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>

  <!-- Latest compiled and minified CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u"
    crossorigin="anonymous">

  <!-- Optional theme -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css" integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp"
    crossorigin="anonymous">

  <!-- Latest compiled and minified JavaScript -->
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa"
    crossorigin="anonymous"></script>

   <link href="style.css" rel="stylesheet">
     
</head>

<body>

      <div class="container" style="max-width:940px  !important;">
       <div class="blog-masthead">
        <p>
            <a href="http://2020.middleware-conference.org/"><img src="banner.jpg" width="900" height="208" align='center' ></img></a>
          </p>    
        </div>
     </div>


    <div class="container" style="max-width:940px  !important;">
       
      <div class="blog-header">
        <h1 class="blog-title">Sixth International Workshop on Serverless Computing (WoSC6) 2020</h1>
        <p class="lead blog-description">Part of <a href="http://2020.middleware-conference.org/">ACM/IFIP International Middleware Conference, Dec 7-11, 2020 in TU Delft, The Netherlands.</a></p>
        <p class="blog-description">
          Please visit the <a href="http://www.serverlesscomputing.org/workshops/">previous workshops website</a> to see what you can expect. 
        </p>
      </div>

      <div class="row">
        <div class="col-sm-12 blog-main">
     <div class="blog-post">

      <h3 id='news'>News</h3>

      <p>
        2020-11-20: <a href="#program">Preliminary workshop program</a>  is available.
        <br/>
        2020-10-14: Final Camera-Ready Manuscript <a href="./cfp/index.html#dates">extended to October 16, 2020</a>
        <br/>
        2019-10-07: Extended <a href="./cfp/index.html#dates">notification date</a>
        <br/>
        2019-10-05: <a href="./cfp/index.html#dates">Update notifications and camera ready dates</a>
        <br/>
        2019-09-08: <a href="./cfp/index.html#dates">Submission deadline extended</a>
        <br/>
        2019-06-29: <a href="./cfp/index.html">CFP available</a>
      </p>

      


  <h2 id='intro'>Welcome</h2>

  <p>
    Over the last four to five years, Serverless Computing (Serverless) has gained an enthusiastic following in industry as a compelling paradigm for the deployment of cloud applications, and is enabled by the recent shift of enterprise application architectures to containers and microservices. Many of the major cloud vendors have released serverless platforms, including Amazon Lambda, Google Cloud Functions, Microsoft Azure Functions, IBM Cloud Functions. 
    Open source projects are gaining popularity in providing serverless computing as a service. In particular Kubernetes gained in popularity in enterprise and in academia. Several open source projects such as OpenFaaS and Knative aim to provide developers with serverless experience on top of Kubernetes by hiding low-level details of Kubernetes and add new capabilities such as supporting event-driven serverless cloud-native applications. This workshop brings together researchers and practitioners to discuss their experiences and thoughts on future directions of serverless research.

</p>

<p>
  Serverless architectures offer different tradeoffs in terms of control, cost, and flexibility compared to distributed applications built on an Infrastructure as a Service (IaaS) substrate. For example, a serverless architecture requires developers to more carefully consider the resources used by their code (time to execute, memory used, etc.) when modularizing their applications. This is in contrast to concerns around latency, scalability, and elasticity, which is where significant development effort has traditionally been spent when building cloud services. In addition, tools and techniques to monitor and debug applications aren't applicable in serverless architectures, and new approaches are needed. As well, test and development pipelines may need to be adapted. Another decision that developers face is the appropriateness of the serverless ecosystem to their application requirements. A rich ecosystem of services built into the platform is typically easier to compose and would offer better performance. However, composing external services may be unavoidable, and in such cases, many of the benefits of serverless disappear, including performance and availability guarantees. This presents an important research challenge, and it is not clear how existing results and best practices, such as workflow composition research, can be applied to composition in a serverless environment.
</p>




<h2 id='program'>Workshop program</h2>

<p>Date: December 8 (Tuesday) [<a href="https://2020.middleware-conference.org/conference-program.html">confirmed</a>]</p>

<p>Time: tentative  10am ET (4pm in Europe) and ending about 5pm ET (11pm in Europe)</p>

<p>Workshop location:  virtual </p>

<p><b>Preliminary schedule</b> 
</p>

<p>
  10am-noon ET (4pm-6pm in Europe): opening remarks, keynote, talks 
</p>


<p>
  noon-1pm ET (6pm-7pm in Europe): break (lunch, maybe demos) 
</p>

<p>
  1pm-3pm ET (7pm-9pm in Europe): talks 
</p>

<p>
  3pm-3:30pm ET (9pm-9:30pm in Europe): short break (maybe demos)
</p>

<p>
  3:30pm-5pm ET (9:30pm-11pm in Europe): last talks and panel, final remarks
</p>


<h4>Invited speaker</h4>

<p>TBD
 
</p>


<h4>Paper presentations</h4>

<p>
  Each talk is 10 minutes with 5 mintues for questions and answers (each talk to not take longer than 15 minutes).
</p>

<p>
  We will be very strict about keeping talks on schedule as people may want ot join for the particualr talk only.
</p>

<p>
  <a href='#p1'>Temporal Performance Modelling of Serverless Computing Platforms</a>

</p><p>

  <a href='#p2'>Implications of Public Cloud Resource Heterogeneity for Inference Serving
  </a>

</p><p>

  <a href='#p3'>Resource Management for Cloud Functions with Memory Tracing, Profiling and Autotuning
  </a>

</p><p>

  <a href='#p4'>An Evaluation of Serverless Data Processing Frameworks
  </a>

</p><p>

  <a href='#p5'>Evaluation of Network File System as a Shared Data Storage in Serverless Computing
  </a>

</p><p>

  <a href='#p6'>Active-Standby for High-Availability in FaaS 	
  </a>
<br/>

</p><p>

  <a href='#p7'>ACE: Just-in-time Serverless Software Component Discovery Through Approximate Concrete Execution 
  </a>

</p><p>

  <a href='#p8'>Serverless Isn't Server-Less: Measuring and Exploiting Resource Variability on Cloud FaaS Platforms
  </a>
 	
</p><p>

  <a href='#p9'>Towards Federated Learning using FaaS Fabric
  </a>
 	
</p><p>

  <a href='#p10'>Bringing scaling transparency to Proteomics applications with serverless computing 
  </a>

</p><p>

  <a href='#p11'>Proactive Serverless Function Resource Management
  </a>
 
</p><p>

  <a href='#p12'>The Serverless Application Analytics Framework: Enabling Design Trade-off Evaluation for Serverless Software
  </a>
 
</p>

<h4 id="panel">  Panel
  </h4>

  <p>TBD</p>

  <h4 id="demos">Demos
  </h4>

  <p>TBD</p>
    
  <h4 id="posters">Posters
  </h4>

  <p>TBD</p>

  <h2 id="papers">Papers abstracts</h2>


  <h3 id='p1'>
    Temporal Performance Modelling of Serverless Computing Platforms
  </h3>
  
  <p>Presenter: N. Mahmoudi

  </p>
  
  <p>
    Authors: N. Mahmoudi, H. Khazaei
  </p>
  
  <p> Abstract:
    Analytical performance models have been shown very efficient in analyzing, predicting, and improving the performance of distributed computing systems. However, there is a lack of rigorous analytical models for analyzing the transient behaviour of serverless computing platforms, which is expected to be the dominant computing paradigm in cloud computing. Also, due to its unique characteristics and policies, performance models developed for other systems cannot be directly applied to modelling these systems.

    In this work, we propose an analytical performance model that is capable of predicting several key performance metrics for serverless workloads using only their average response time for warm and cold requests. The introduced model uses realistic assumptions, which makes it suitable for online analysis of real-world platforms. We validate the proposed model through extensive experimentation on AWS Lambda. Although we focus primarily on AWS Lambda due to its wide adoption in our experimentation, the proposed model can be leveraged for other public serverless computing platforms with similar auto-scaling policies, e.g., Google Cloud Functions, IBM Cloud Functions, and Azure Functions.
  </p>

  <p>Presentation 
    [<a href='presentations/p1.pdf'>pdf</a>] 
    [<a href='presentations/p1.pptx'>pptx</a>]
  <br/>
  Video recording    
  [<a href='https://youtu.be/E5KigIq0Z1E'>lightning</a>] 
  [<a href='https://youtu.be/9r3j_1B5t8c'>talk</a>] 
  <!--
  [<a href=''></a>extended] 
  -->
  </p>
  


  <h3 id='p2'>
    Implications of Public Cloud Resource Heterogeneity for Inference Serving 
  </h3>
  
  <p>Presenter: 

  </p>
  
  <p>
    Authors: J. Gunasekaran, C. Mishra, P. Thinakaran, M. Kandemir, C. Das

  </p>
  
  <p> Abstract:
    We are witnessing an increasing trend towards using Machine Learning (ML) based prediction systems, spanning across different application domains, including product recommendation systems, personal assistant devices, facial recognition, etc. These applications typically have diverse requirements in terms of accuracy and response latency, that have a direct impact on the cost of deploying them in a public cloud. Furthermore, the deployment cost also depends on the type of resources being procured, which by themselves are heterogeneous in terms of provisioning latencies and billing complexity. Thus, it is strenuous for an inference serving system to choose from this confounding array of resource types and model types to provide low-latency and cost-effective inferences. In this work we quantitatively characterize the cost, accuracy and latency implications of hosting ML inferences on different public cloud resource offerings. Our evaluation shows that, prior work does not solve the problem from both dimensions of model and resource heterogeneity. Hence, we argue that to address this problem, we need to holistically solve the issues that arise when trying to combine both model and resource heterogeneity towards optimizing for application constraints. Towards this, we discuss the design and implications of a self-managed inference serving system, which can optimize the application requirements based on public cloud resource characteristics.
  </p>

  <p>Presentation 
    [<a href='presentations/'></a>pdf] 
    [<a href='presentations/'></a>pptx]
  <br/>
  Video recording    
  <!--
  [<a href=''></a>lightning] 
  -->
  [<a href=''></a>talk] 
  <!--
  [<a href=''></a>extended] 
  -->
  </p>
  
 

  <h3 id='p3'>
    Resource Management for Cloud Functions with Memory Tracing, Profiling and Autotuning 
  </h3>
  
  <p>Presenter: 

  </p>
  
  <p>
    Authors: J. Spillner
  </p>
  
  <p> Abstract:
    Application software provisioning evolved from monolithic designs towards differently designed abstractions including serverless applications. The promise of that abstraction is that developers are free from infrastructural concerns such as instance activation and autoscaling. Today's serverless architectures based on FaaS are however still exposing developers to explicit low-level decisions about the amount of memory to allocate for the respective cloud functions. In many cases, guesswork and ad-hoc decisions determine the values a developer will put into the configuration. We contribute tools to measure the memory consumption of a function in various Docker, OpenFaaS and GCF/GCR configurations over time and to create trace profiles that advanced FaaS engines can use to autotune memory dynamically. Moreover, we explain how pricing forecasts can be performed by connecting these traces with a FaaS characteristics knowledge base.
  </p>

  <p>Presentation 
    [<a href='presentations/faasmemautotuning-slides.pdf'>pdf</a>] 
  <br/>
  Video recording    
  [<a href='https://www.youtube.com/watch?v=qOc64o68rI8'>lightning</a>] 
  [<a href='https://www.youtube.com/watch?v=ESb-DKQDOwo'>talk</a>] 
  <!--
  [<a href=''></a>extended] 
  -->
  </p>
  
 

  <h3 id='p4'>
    An Evaluation of Serverless Data Processing Frameworks
  </h3>
  
  <p>Presenter: 

  </p>
  
  <p>
    Authors: S. Werner, R. Girke, J. Kuhlenkamp
  </p>
  
  <p> Abstract:
    Serverless computing is a promising cloud execution model that significantly simplifies cloud users’ operational concerns by offering features such as auto-scaling and a pay-as-you-go cost model.
Consequently, serverless systems promise to provide an excellent fit for ad-hoc data processing. Unsurprisingly, numerous serverless systems/frameworks for data processing emerged recently from research and industry. 
However, systems researchers, decision-makers, and data analysts are unaware of how these serverless systems compare to each other.

In this paper, we identify existing serverless frameworks for data processing. We present a qualitative assessment of different system architectures and an experiment-driven quantitative comparison, including performance, cost, and usability using the TPC-H benchmark.
Our results show that the three publicly available serverless data processing frameworks outperform a comparatively sized Apache Spark cluster in terms of performance and cost for ad-hoc queries on cold data.
  </p>

  <p>Presentation 
    [<a href='presentations/'></a>pdf] 
    [<a href='presentations/'></a>pptx]
  <br/>
  Video recording    
  <!--
  [<a href=''></a>lightning] 
  -->
  [<a href=''></a>talk] 
  <!--
  [<a href=''></a>extended] 
  -->
  </p>
  
 

  <h3 id='p5'>
    Evaluation of Network File System as a Shared Data Storage in Serverless Computing
  </h3>
  
  <p>Presenter: 

  </p>
  
  <p>
    Authors: J. Choi, K. Lee
  </p>
  
  <p> Abstract:
    Fully-managed cloud and Function-as-a-Service (FaaS) services allow the wide adoption of serverless computing for various cloud-native applications. Despite the many advantages that serverless computing provides, no direct connection support exists between function run-times, and it is a barrier for data-intensive applications. To overcome this limitation, the leading cloud computing vendor Amazon Web Services (AWS) has started to support mounting the network file system (NFS) across different function run-times. This paper quantitatively evaluates the performance of accessing NFS storage from multiple function run-times and compares the performance with other methods of sharing data among function run-times. Despite the great qualitative benefits of the approach, the limited I/O bandwidth of NFS storage can become a bottleneck, especially when the number of concurrent access from function run-times increases.
  </p>

  <p>Presentation 
    [<a href='presentations/'></a>pdf] 
    [<a href='presentations/'></a>pptx]
  <br/>
  Video recording    
  <!--
  [<a href=''></a>lightning] 
  -->
  [<a href=''></a>talk] 
  <!--
  [<a href=''></a>extended] 
  -->
  </p>
  
 

  <h3 id='p6'>
    Active-Standby for High-Availability in FaaS 	
  </h3>
  
  <p>Presenter: 

  </p>
  
  <p>
    Authors: Y. Bouizem, D. Dib, N. Parlavantzas, C. Morin
  </p>
  
  <p> Abstract:
    Serverless computing is becoming more and more attractive for cloud solution architects and developers. This new computing paradigm relies on Function-as-a-Service (FaaS) platforms that enable deploying functions without being concerned with the underlying infrastructure. An important challenge in designing FaaS platforms is ensuring the availability of deployed functions. Existing FaaS platforms address this challenge principally through retrying function executions. In this paper, we propose and implement an alternative fault-tolerance approach based on active-standby failover. Results from an experimental evaluation show that our approach increases availability and performance compared to the retry-based approach.
  </p>

  <p>Presentation 
    [<a href='presentations/'></a>pdf] 
    [<a href='presentations/'></a>pptx]
  <br/>
  Video recording    
  <!--
  [<a href=''></a>lightning] 
  -->
  [<a href=''></a>talk] 
  <!--
  [<a href=''></a>extended] 
  -->
  </p>
  
 

  <h3 id='p7'>
    ACE: Just-in-time Serverless Software Component Discovery Through Approximate Concrete Execution 
  </h3>
  
  <p>Presenter: A. Byrne

  </p>
  
  <p>
    Authors: A. Byrne, S. Nadgowda, A. Coskun
  </p>
  
  <p> Abstract:
    While much of the software running on today's serverless platforms is written in easily-analyzed high-level interpreted languages, many performance-conscious users choose to deploy their applications as container-encapsulated compiled binaries on serverless container platforms such as AWS Fargate or Google Cloud Run. Modern CI/CD workflows make this deployment process nearly-instantaneous, leaving little time for in-depth manual application security reviews. This combination of opaque binaries and rapid deployment prevents cloud developers and platform operators from knowing if their applications contain outdated, vulnerable, or legally-compromised code. This paper proposes Approximate Concrete Execution (ACE), a just-in-time binary analysis technique that enables automatic software component discovery for serverless binaries. Through classification and search engine experiments with common cloud software packages, we find that ACE scans binaries 5.2x faster than a state-of-the-art binary analysis tool, minimizing the impact on deployment and cold-start latency while maintaining comparable recall.
  </p>

  <p>Presentation 
    [<a href='presentations/p7.pdf'>pdf</a>] 
    [<a href='presentations/p7.pptx'>pptx</a>]
  <br/>
  Video recording    
  <!--
  [<a href=''></a>lightning] 
  -->
  [<a href='https://youtu.be/mctma7mcLCs'>talk</a>] 
  <!--
  [<a href=''></a>extended] 
  -->
  </p>
  
 

  <h3 id='p8'>
    Serverless Isn't Server-Less: Measuring and Exploiting Resource Variability on Cloud FaaS Platforms
  </h3>
  
  <p>Presenter: 

  </p>
  
  <p>
    Authors: S. Ginzburg, M. Freedman
  </p>
  
  <p> Abstract:
    Serverless computing in the cloud, or functions as a service (FaaS), poses new
and unique systems design challenges. Serverless offers improved
programmability for customers, yet at the cost of increased design complexity
for cloud providers.  One such challenge is effective and consistent resource
management for serverless platforms, the implications of which we explore in
this paper.

In this paper, we conduct one of the first detailed in situ measurement studies of performance variability in AWS Lambda. We show that the observed variations in performance are not only significant, but stable enough to exploit.

We then design and evaluate an end-to-end system that takes advantage of this resource variability to exploit the FaaS consumption-based pricing model, in which functions are charged based on their fine-grain execution time rather than actual low-level resource consumption. By using both light-weight resource probing and function execution times to identify attractive servers in serverless platforms, customers of FaaS services can cause their functions to execute on better performing servers and realize a cost savings of up to 13% in the same AWS region.
  </p>

  <p>Presentation 
    [<a href='presentations/'></a>pdf] 
    [<a href='presentations/'></a>pptx]
  <br/>
  Video recording    
  <!--
  [<a href=''></a>lightning] 
  -->
  [<a href=''></a>talk] 
  <!--
  [<a href=''></a>extended] 
  -->
  </p>
  
 

  <h3 id='p9'>
    Towards Federated Learning using FaaS Fabric
  </h3>
  
  <p>Presenter: Mohak Chadha

  </p>
  
  <p>
    Authors: M. Chadha, A. Jindal, M. Gerndt
  </p>
  
  <p> Abstract:
    Federated learning (FL) enables resource-constrained edge devices to learn a shared Machine Learning (ML) or Deep Neural Network (DNN) model, while keeping the training data local and providing privacy, security, and economic benefits. However, building a shared model for heterogeneous devices such as resource-constrained edge and cloud makes the efficient management of FL-clients challenging. Furthermore, with the rapid growth of FL-clients, the scaling of FL training process is also difficult.

In this paper, we propose a possible solution to these challenges: federated learning over a combination of connected Function-as-a-Service platforms, i.e., FaaS fabric offering a seamless way of extending FL to heterogeneous devices. Towards this, we present FedKeeper, a tool for efficiently managing FL over FaaS fabric. We demonstrate the functionality of FedKeeper by using three FaaS platforms through an image classification task with a  varying number of devices/clients, different stochastic optimizers, and local computations (local epochs).
  </p>

  <p>Presentation 
    [<a href='presentations/WoSC_2020_Presentation_P9.pdf'></a>pdf] 
  <br/>
  Video recording    
  <!--
  [<a href=''></a>lightning] 
  -->
  [<a href='https://youtu.be/CjK4mevTTTc'></a>talk] 
  <!--
  [<a href=''></a>extended] 
  -->
  </p>
  
 

  <h3 id='p10'>
    Bringing scaling transparency to Proteomics applications with serverless computing 
  </h3>
  
  <p>Presenter: 

  </p>
  
  <p>
    Authors: M. Mirabelli, P. Lopez, G. Vernik
  </p>
  
  <p> Abstract:
    Scaling transparency means that applications can expand in scale without changes to the system structure or the application algorithms. Serverless Computing's inherent auto-scaling support and fast function launching is ideally suited to support scaling transparency in different domains.

In particular, Proteomic applications could considerably benefit from scaling transparency and serverless technologies due to their high concurrency requirements. Therefore, the auto-provisioning nature of serverless platforms makes this computing model an alternative to satisfy dynamically the resources required by protein folding simulation processes. However, the transition to these architectures must face challenges: they should show comparable performance and cost to code running in Virtual Machines (VMs).

In this article, we demonstrate that Proteomics applications implemented with the Replica Exchange algorithm can be moved to serverless settings guaranteeing scaling transparency. We also validate that we can reduce the total execution time by around forty percent with comparable cost to cluster technologies (Work Queue) over VMs.
  </p>

  <p>Presentation 
    [<a href='presentations/'></a>pdf] 
    [<a href='presentations/'></a>pptx]
  <br/>
  Video recording    
  <!--
  [<a href=''></a>lightning] 
  -->
  [<a href=''></a>talk] 
  <!--
  [<a href=''></a>extended] 
  -->
  </p>
  
 

  <h3 id='p11'>
    Proactive Serverless Function Resource Management
  </h3>
  
  <p>Presenter: E. Hunhoff 

  </p>
  
  <p>
    Authors: E. Hunhoff, S. Irshad, V. Thurimella, A. Tariq, E. Rozner
  </p>
  
  <p> Abstract:
    This paper introduces a new primitive to serverless language runtimes called freshen. With freshen, developers or providers specify functionality to perform before a given function executes. This proactive technique allows for overheads associated with serverless functions to be mitigated at execution time, which improves function responsiveness. We show various predictive opportunities exist to run freshen within reasonable time windows. A high-level design and implementation are described, along with preliminary results to show the potential benefits of our scheme.
  </p>

  <p>Presentation 
    [<a href='presentations/p11.pdf'></a>pdf] 
    [<a href='presentations/p11.ppt'></a>pptx]
  <br/>
  Video recording    
  <!--
  [<a href=''></a>lightning] 
  -->
  [<a href='https://youtu.be/fMQvhkuqnmc'></a>talk] 
  <!--
  [<a href=''></a>extended] 
  -->
  </p>
  
 

  <h3 id='p12'>
    The Serverless Application Analytics Framework: Enabling Design Trade-off Evaluation for Serverless Software
  </h3>
  
  <p>Presenter: 

  </p>
  
  <p>
    Authors: R. Cordingly, H. Yu, V. Hoang, Z. Sadeghi, D. Foster, D. Perez, R. Hatchett, W. Lloyd
  </p>
  
  <p> Abstract:
    To help better understand factors that impact performance on Function-as-a-Service (FaaS) platforms we have developed the Serverless Application Analytics Framework (SAAF). SAAF provides a reusable framework supporting multiple programming languages that developers can integrate into a function’s package for deployment to multiple commercial and open source FaaS platforms. SAAF improves the observability of FaaS function deployments by collecting forty-eight distinct metrics to enable developers to profile CPU and memory utilization, monitor infrastructure state, and observe platform scalability. In this paper, we describe SAAF in detail and introduce supporting tools highlighting important features and how to use them. Our client application, FaaS Runner, provides a tool to orchestrate workloads and automate the process of conducting experiments across FaaS platforms. We provide a case study demonstrating the integration of SAAF into an existing open source image processing pipeline built for AWS Lambda. Using FaaS Runner, we automate experiments and acquire metrics from SAAF to profile each function of the pipeline to evaluate performance implications. Finally, we summarize contributions using our tools to evaluate implications of different programming languages for serverless data processing, and to build performance models to predict runtime for serverless workloads.
  </p>

  <p>Presentation 
    [<a href='presentations/'></a>pdf] 
    [<a href='presentations/'></a>pptx]
  <br/>
  Video recording    
  <!--
  [<a href=''></a>lightning] 
  -->
  [<a href=''></a>talk] 
  <!--
  [<a href=''></a>extended] 
  -->
  </p>
  
     

<h2>Workshop call for papers</h2>
  <p>
    <a href="./cfp/index.html">Call For Papers (CFP)</a>
  </p>

  
<h2 id='org'>Organization</h2>

<h3>Workshop co-chairs</h3>

  <p>
Paul Castro, IBM Research
<br/>
Pedro García López, University Rovira i Virgili 
<br/>
Vatche Ishakian, IBM Research
<br/>
Vinod Muthusamy, IBM Research
<br/>
Aleksander Slominski, IBM Research
  </p>


  <h3>Steering Committee</h3>
  
  <p>
  Geoffrey Fox, Indiana University 
  <br/>        
  Dennis Gannon, Indiana University &amp; Formerly Microsoft Research
  <br/>
  Arno Jacobsen, MSRG (Middleware Systems Research Group)
  <br/>
    </p>
  
  <h3>Program Committee (tentative)</h3>

<p>
  Gul Agha, University of Illinois at Urbana-Champaign<br/>
  Azer Bestavros, Boston University<br/>
  Flavio Esposito, Saint Louis University<br/>
  Rodrigo Fonseca, Brown University<br/>
  Ian Foster, University of Chicago and Argonne National Laboratory<br/>
  Geoffrey Fox, Indiana University<br/>
  Dennis Gannon, Indiana University &amp; Formerly Microsoft Research<br/>
  Pedro Garcia Lopez, Universitat Rovira i Virgili (Spain)<br/>
  Arno Jacobsen, MSRG (Middleware Systems Research Group)<br/>
  Ali Kanso, Microsoft<br/>
  Wes Lloyd, University of Washington Tacoma<br/>
  Maciej Malawski, AGH University of Science and Technology, Poland <br/>
  Pietro Michiardi, Eurecom<br/>
  Lucas Nussbaum, LORIA, France<br/>
  Maciej Pawlik, Academic Computer Centre CYFRONET of the University of Science and Technology in Cracow<br/>
  Per Persson, Ericsson Research<br/>
  Peter Pietzuch, Imperial College<br/>
  Rodric Rabbah, Nimbella and Apache OpenWhisk<br/>
  Eric Rozner, University of Colorado Boulder<br/>
  Josef Spillner, Zurich University of Applied Sciences<br/>
  Rich Wolski, University of California, Santa Barbara<br/>
</p>

    <h2 id="previous">Previous workshop</h2>

    <p>
      <a href="../wosc5/">Fifth International Workshop on Serverless Computing (WoSC)</a> in UC Davis, CA, USA on Decemeber 9, 2019. In conjunction with <a href="http://2019.middleware-conference.org/">20th ACM/IFIP International Middleware Conference</a>.
    </p>
  
  <p>
    <a href="../wosc4/">Fourth International Workshop on Serverless Computing (WoSC)</a> in  Zurich, Zurich, Switzerland on Decemeber 20, 2018. In conjunction with <a href="http://ucc-conference.org/category/basics.html">11th IEEE/ACM UCC</a> and <a href="http://bdcat-conference.org/category/basics.html">5th IEEE/ACM BDCAT</a>.
  </p>

  <p>
    <a href="../wosc3/">Third  International Workshop on Serverless Computing (WoSC)</a> in  San Francisco, CA, USA on July 2nd 2018 In conjunction with <a href="http://conferences.computer.org/cloud/2018/">IEEE CLOUD 2018</a> affiliated with 2018 IEEE World Congress on Services (IEEE SERVICES 2018).
  </p>

  <p>
        <a href="../wosc2/">Second  International Workshop on Serverless Computing (WoSC) 2017</a> in  Las Vegas, NV, USA on December 12th, 2017 part of <a href="http://2017.middleware-conference.org">Middleware 2017</a>.
      </p>
    
  <p>
    <a href="../wosc1/">First International Workshop on Serverless Computing (WoSC) 2017</a> in Atlanta, GA, USA on June 5th, 2017 part of <a href="http://icdcs2017.gatech.edu/">ICDCS 2017</a>.
  </p>


<!--
<h2 id="forum">Forum</h2>
<p>
  <iframe id="forum_embed"
  src="javascript:void(0)"
  scrolling="no"
  frameborder="0"
  width="900"
  height="700">
</iframe>
<script type="text/javascript">
  document.getElementById('forum_embed').src =
     'https://groups.google.com/forum/embed/?place=forum/future-compute'
     + '&showsearch=true&showpopout=true&showtabs=false'
     + '&parenturl=' + encodeURIComponent(window.location.href);
</script>
</p>
-->


<h2 id="tweets">Tweets about workshop</h2>
<p>
Please use hashtags <a href="https://twitter.com/search?q=wosc%20serverless">#wosc6 #serverless</a>
</p>

<p>
  <!--
  <a class="twitter-timeline" data-dnt="true" href="https://twitter.com/search?q=wosc%20serverless" data-widget-id="958776427733757955">Tweets about WoSC serverless</a>
  <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>

  -->

  <a class="twitter-timeline" href="https://twitter.com/wosc17?ref_src=twsrc%5Etfw">Tweets by wosc17</a> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</p>

          </div><!-- /.blog-post -->
      </div><!-- /.row -->

    </div><!-- /.container -->

</body>
</html>
